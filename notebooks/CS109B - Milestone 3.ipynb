{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CS109B - Milestone 3\n",
    "Authors: Stephanie von Klot-Heydenfeldt, Roberto Vitillo, Alessio Placitelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alessio\\Anaconda2\\lib\\site-packages\\skimage\\viewer\\utils\\core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "import sys\n",
    "import os\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tables\n",
    "\n",
    "sys.path.append(os.path.realpath('../lib'))\n",
    "\n",
    "from tmdbw import TMDBW\n",
    "from pandas.io.json import json_normalize\n",
    "from skimage.viewer import ImageViewer\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import transform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "### Building a shared train/test set\n",
    "As described in Milestone 2, we built a library to download movie posters and metadata from TMDB. However, scraping the data and making the heavy poster data file available to all the team members was only the first step. We needed a way to correctly reproduce the very same train/test splits on every machine, with a balanced representation of all the available movie genres.\n",
    "\n",
    "To satisfy these requirements, since we couldn’t find any suitable function in sklearn, we decided to implement our own stratified iterative sampling function. Here’s how the algorithm works:\n",
    "\n",
    "1. Enumerate all the possible genres available in the dataset and count their frequency.\n",
    "2. Sort them from the least frequent to the most frequent genre.\n",
    "3. For each sorted genre:\n",
    "  * Check if the label was already partially sampled. This can happen as movies have multiple labels.\n",
    "  * Compute the number of samples we expect to have in the train set for this label by multiplying the requested ratio of train set samples with the number of occurrences for this label.\n",
    "    * If the number of samples with this label is greater than the number of expected samples, move on to the next genre\n",
    "  * Compute the number of samples that we need to add for this label, as a difference between the expected number of samples with the current label and the number of desired samples.\n",
    "  * Randomly sample from the original dataset, add them to the train set and remove them from the original dataset.\n",
    "  * Move to the next genre.\n",
    "\n",
    "This algorithm allows to have train/test sets that contain the same proportion of labels that can be found in the original dataset. It’s trivial to produce the same results with this algorithm by specifying the random seed of the sampling algorithm.\n",
    "\n",
    "### The process\n",
    "After generating the train and test sets used to evaluate our models, we started investigating their performance with various traditional machine learning algorithms.\n",
    "\n",
    "Since we have a multi-label problem, we decided to use a one-vs-the rest classification strategy, basically training a model for each label: each model having the the Y for the related label set to a positive value and the rest being negative.\n",
    "\n",
    "This strategy is implemented by the sklearn [OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) class, which plays nicely with the [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) class, conveniently allowing to model multi-label problems with a few lines of code.\n",
    "\n",
    "Each investigated machine learning algorithm was fine-tuned by performing an exhaustive search over specified hyperparameter values, with cross-validation.\n",
    "\n",
    "# Part 1 - Investigate movie metadata\n",
    "We created explanatory features based on the keywords, overview and tagline that were provided for the movies. We included features based on one combined bag of words, including those words that occurred at least 100 times total. We also encoded the actors as dummy variables and kept those that appeared more than 50 times as either the first or the secondary actor in the data. The year of the movie release, runtime, revenue and budget were included as numerical variables.\n",
    "\n",
    "We performed stratified sampling of the data for creation of a training set that consisted of 10% of the data.\n",
    "On the standardized training data with the features described above we implemented multi-label SVM (one-vs-the rest) to predict genre and determined the best parameters using grid search with 5 fold cross validation.  We report performance (genre specific precision, recall, accuracy and summary measures as described below) on the test data (90% of the dataset).  We compared these performance measures with a naive classifier that predicts genre randomly. \n",
    "\n",
    "Similarly we tuned a random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import TMDB data\n",
    "We built an external library to import, so we just import the Tmdb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TMDB_all = pd.read_pickle(\"../data/data_export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove missing values and de-duplicate movie data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 duplicated movies.\n",
      "The shape of the clean metadata dataset is (9790, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>adult</th>\n",
       "      <th>budget</th>\n",
       "      <th>director</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>language</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Emma Watson</td>\n",
       "      <td>Dan Stevens</td>\n",
       "      <td>False</td>\n",
       "      <td>160000000</td>\n",
       "      <td>Bill Condon</td>\n",
       "      <td>[Fantasy, Music, Romance]</td>\n",
       "      <td>tt2771200</td>\n",
       "      <td>france,magic,castle,fairy tale,musical,curse,c...</td>\n",
       "      <td>en</td>\n",
       "      <td>A live-action adaptation of Disney's version o...</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>959241034</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Be our guest.</td>\n",
       "      <td>Beauty and the Beast</td>\n",
       "      <td>321612</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alec Baldwin</td>\n",
       "      <td>Miles Christopher Bakshi</td>\n",
       "      <td>False</td>\n",
       "      <td>125000000</td>\n",
       "      <td>Tom McGrath</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>tt3874544</td>\n",
       "      <td>family relationships,unreliable narrator,3d</td>\n",
       "      <td>en</td>\n",
       "      <td>A story about how a new baby's arrival impacts...</td>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>137547590</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Born leader</td>\n",
       "      <td>The Boss Baby</td>\n",
       "      <td>295693</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        actor1                    actor2  adult     budget  \\\n",
       "0      0   Emma Watson               Dan Stevens  False  160000000   \n",
       "1      1  Alec Baldwin  Miles Christopher Bakshi  False  125000000   \n",
       "\n",
       "      director                       genres    imdb_id  \\\n",
       "0  Bill Condon    [Fantasy, Music, Romance]  tt2771200   \n",
       "1  Tom McGrath  [Animation, Comedy, Family]  tt3874544   \n",
       "\n",
       "                                            keywords language  \\\n",
       "0  france,magic,castle,fairy tale,musical,curse,c...       en   \n",
       "1        family relationships,unreliable narrator,3d       en   \n",
       "\n",
       "                                            overview release_date    revenue  \\\n",
       "0  A live-action adaptation of Disney's version o...   2017-03-16  959241034   \n",
       "1  A story about how a new baby's arrival impacts...   2017-03-23  137547590   \n",
       "\n",
       "   runtime        tagline                 title  tmdb_id  release_year  \n",
       "0    129.0  Be our guest.  Beauty and the Beast   321612        2017.0  \n",
       "1     97.0    Born leader         The Boss Baby   295693        2017.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Found {} duplicated movies.\".format(TMDB_all.duplicated('tmdb_id').sum()))\n",
    "\n",
    "# Keep only the first of duplicate observations.\n",
    "TMDB_clean = TMDB_all.drop_duplicates(['tmdb_id'])\n",
    "\n",
    "# Create a release year variable out of the release_date.\n",
    "TMDB_clean['release_year'] = pd.to_numeric(TMDB_clean['release_date'].str[:4])\n",
    "\n",
    "# Remove observations with some missing values in the fields\n",
    "# we care for.\n",
    "TMDB_clean = TMDB_clean.dropna(subset = [\"director\", \"overview\", \"actor2\", \"release_year\"])\n",
    "\n",
    "# Drop the \"producer\" and \"writer\" columns, they have too many missings\n",
    "drop_variables = [i for i, item in enumerate(TMDB_all.isnull().mean()) if item > 0.2]\n",
    "TMDB_clean = TMDB_clean.drop(TMDB_clean.columns[drop_variables], axis = 1)\n",
    "\n",
    "# Reset the index.\n",
    "TMDB_clean.reset_index(inplace = True)\n",
    "\n",
    "print(\"The shape of the clean metadata dataset is {}\".format(TMDB_clean.shape))\n",
    "\n",
    "TMDB_clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This should use tmdb.get_genres()\n",
    "GENRE_LIST = [\n",
    "    'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
    "    'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History',\n",
    "    'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
    "    'TV Movie', 'Thriller', 'War', 'Western'\n",
    "]\n",
    "\n",
    "# Build the binarized labels.\n",
    "label_binarizer = MultiLabelBinarizer()\n",
    "binarized_y = label_binarizer.fit_transform(TMDB_clean['genres'])\n",
    "Y = pd.DataFrame(binarized_y, columns=label_binarizer.classes_)\n",
    "\n",
    "# Create a new table without the undesired colums.\n",
    "X = TMDB_clean.drop([\"genres\", \"imdb_id\", \"tmdb_id\", \"adult\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use bag of words for the keywords / overview /tagline columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 618 for: allwords\n",
      "     count                ngram\n",
      "315   2244                 life\n",
      "333   2105                 love\n",
      "379   1993                  new\n",
      "343   1799                  man\n",
      "605   1727                world\n",
      "598   1669                woman\n",
      "193   1534                 film\n",
      "614   1528                young\n",
      "177   1478               family\n",
      "35    1270                based\n",
      "585   1236                  war\n",
      "514   1194                story\n",
      "546   1188                 time\n",
      "435   1168         relationship\n",
      "182   1033               father\n",
      "367   1020               murder\n",
      "460    976               school\n",
      "125    959                death\n",
      "388    896                  old\n",
      "595    839                 wife\n",
      "478    811                  sex\n",
      "363    795               mother\n",
      "465    785               secret\n",
      "409    783               police\n",
      "138    769             director\n",
      "209    751              friends\n",
      "611    744                years\n",
      "493    730                  son\n",
      "118    724             daughter\n",
      "221    723                 girl\n",
      "..     ...                  ...\n",
      "206    112              freedom\n",
      "161    111              english\n",
      "376    111                 need\n",
      "551    111             training\n",
      "78     111           characters\n",
      "437    110               remote\n",
      "314    110                  let\n",
      "487    110  sister relationship\n",
      "508    110               states\n",
      "130    110               desire\n",
      "42     109            beginning\n",
      "190    109              fighter\n",
      "280    109                 join\n",
      "281    109                joins\n",
      "294    109                 kiss\n",
      "286    109            kidnapped\n",
      "392    108                 pair\n",
      "456    107             ruthless\n",
      "601    107                  won\n",
      "3      107         accidentally\n",
      "154    107          dying death\n",
      "554    106              travels\n",
      "47     106               better\n",
      "468    105            seemingly\n",
      "431    105                ready\n",
      "197    105               follow\n",
      "224    103                given\n",
      "162    102               entire\n",
      "342    101          male nudity\n",
      "375    101                 near\n",
      "\n",
      "[618 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleanup_text(s):\n",
    "    s = s.lower()\n",
    "    s = s.replace('-', ' ')\n",
    "    s = s.replace(')', ' ')\n",
    "    s = s.replace('(', ' ')\n",
    "    s = s.replace(',', ' ')\n",
    "    s = s.replace('.', ' ')\n",
    "    s = s.replace('\"', ' ')\n",
    "    s = s.replace(' br ', '')\n",
    "    s = s.replace(' quot ', ' ')\n",
    "    s = s.replace(' amp ', ' and ')\n",
    "    s = s.replace(' s ', \"'s \")\n",
    "    s = s.replace(' t ', \"'t \")\n",
    "    s = s.replace(' m ', \"'m \")\n",
    "    s = s.replace(' ve ', \"'ve \")\n",
    "    s = s.replace(' ll ', \"ll \")\n",
    "    s = s.replace(' ', \" \")\n",
    "    s = re.sub(r'(\\d) (\\d{3})', r'\\1,\\2', s)\n",
    "    return s\n",
    "\n",
    "def bag_of_words(feature):\n",
    "    feature_cleaned =  X[feature].apply(cleanup_text)\n",
    "  \n",
    "    vectorizer = CountVectorizer(stop_words='english',\n",
    "                                 min_df = 100,\n",
    "                                 ngram_range=(1,2))\n",
    "    word_counts = vectorizer.fit_transform(feature_cleaned)\n",
    "\n",
    "    feature_names = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    feature_names[::(len(feature_names)/20)]\n",
    "\n",
    "    word_count_sum = pd.DataFrame(word_counts.sum(axis=0).T, columns=['count'])\n",
    "    word_count_sum['ngram'] = feature_names\n",
    "    print \"number of features: \" + str(len(feature_names)) + \" for: \" + str(feature)\n",
    "    print  word_count_sum.sort_values(by=['count'], ascending=[0])\n",
    "    return word_counts, feature_names\n",
    "\n",
    "\n",
    "# Create one big suitcase of words out of all 3 variables\n",
    "X['allwords'] = X[['keywords', 'overview', 'tagline']].apply(lambda x: ','.join(x), axis=1)\n",
    "all_word_counts, all_feature_names = bag_of_words('allwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables of actors\n",
    "\n",
    "Use actor1 and actor2 for this and add both dummy variable matrices, so that the combinations are available per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hot encode actor1 and then actor2\n",
    "actor1_dummies = pd.get_dummies(X[\"actor1\"])\n",
    "actor2_dummies = pd.get_dummies(X[\"actor2\"])\n",
    "\n",
    "#add the two dummy list in order to have both actors\n",
    "actor_dummies =  actor1_dummies.add(actor2_dummies, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9790, 4111), (9790, 5472), (9790, 7808))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor1_dummies.shape, actor2_dummies.shape, actor_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the number of dummy variables by just considering those actors with a certain frequency (N>50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "varlist = ['budget', 'revenue', 'runtime', 'release_year', 'actor1', 'actor2']\n",
    "X_combined = pd.concat([actor_dummies[actor_dummies.sum()[actor_dummies.sum()>50].index],\n",
    "                        pd.DataFrame(all_word_counts.A, columns=all_feature_names),\n",
    "                        pd.DataFrame(X[varlist])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9790, 626)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Build the train, test and validation sets\n",
    "\n",
    "We build a training set that has the same proportion of labels as the full dataset, so that every genre is represented.\n",
    "\n",
    "We start sampling from the least frequent class to the most frequent one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TMDB_binarized_outcome = binarized_y\n",
    "\n",
    "#generate train and test sets\n",
    "def test_train(data, setsize = 0.1):\n",
    "    genre_counts = {}\n",
    "    for genre in label_binarizer.classes_:\n",
    "        genre_counts[genre] = data['genres'].apply(lambda x: genre in x).sum()\n",
    "\n",
    "    # Sort the genres from the least occurring to the most frequent.\n",
    "    num_movies = data.shape[0]\n",
    "    sorted_genres = sorted(genre_counts.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    #for now make training data small, for computational reasons\n",
    "    train_set_size = setsize*1.0\n",
    "\n",
    "    # Generate a train/test set.\n",
    "    train_set = pd.DataFrame()\n",
    "    original_set = data.copy()\n",
    "    for genre, count in sorted_genres:\n",
    "        # Check how many samples have this label in the set.\n",
    "        # The dataframe may be empty on the first run, so account for\n",
    "        # that.\n",
    "        already_sampled = 0\n",
    "        if 'genres' in train_set:\n",
    "            already_sampled = train_set['genres'].apply(lambda x: genre in x).sum()\n",
    "\n",
    "        # If the test set already contains all the samples we expect\n",
    "        # for this label, continue to the next label.\n",
    "        expected_samples = int(math.floor(train_set_size * count))        \n",
    "        if already_sampled >= expected_samples:\n",
    "            continue\n",
    "\n",
    "        # If not, then randomly sample |expected - already_there| samples\n",
    "        num_to_sample = expected_samples - already_sampled\n",
    "        samples = original_set[original_set['genres'].apply(lambda x: genre in x)]\\\n",
    "                                                     .sample(n=num_to_sample, random_state = 42)\n",
    "        # Append the random samples to the train_set\n",
    "        train_set = train_set.append(samples)\n",
    "        # Remove them from the original set, so we don't sample them again\n",
    "        # for a different label.\n",
    "        original_set = original_set.drop(samples.index)\n",
    "        test_set = data.drop(train_set.index)\n",
    "    \n",
    "    \n",
    "    # use the indices above to create the train and test sets of the different data frames\n",
    "    # for this make sure that the indices match\n",
    "    X_train = X_combined.loc[train_set.index]#original dataframe\n",
    "    X_test = X_combined.drop(train_set.index)\n",
    "    Y_train = Y.loc[train_set.index]#hand created labels\n",
    "    Y_test = Y.drop(train_set.index)\n",
    "    \n",
    "    y1_train = MultiLabelBinarizer().fit_transform(data['genres'].loc[train_set.index])\n",
    "    y1_test = MultiLabelBinarizer().fit_transform(data['genres'].drop(train_set.index))\n",
    "    \n",
    "    return X_train, X_test, y1_train, y1_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train01, X_test01, y1_train01, y1_test01, Y_train01, Y_test01 = test_train(TMDB_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find actors that in the training dataset represent always a certain genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Action</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jean-Claude Van Damme</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jet Li</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masako Nozawa</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Action                 0  1  All\n",
       "actor1                          \n",
       "Jean-Claude Van Damme  0  3    3\n",
       "Jet Li                 0  3    3\n",
       "Masako Nozawa          0  3    3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test (only in train data) if actors are predictive of genre, example action\n",
    "subset =pd.crosstab(X_train01.actor1,Y_train01[\"Action\"], margins = True)\n",
    "subset.pred = np.where(((subset.All - subset.iloc[:,1] == 0) & (subset.All>2)), 1,0)\n",
    "subset[subset.pred ==1].sort_values(by=['All'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Comedy</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adam Sandler</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevy Chase</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill Murray</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eddie Murphy</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jack Black</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jim Carrey</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Johnny Knoxville</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike Myers</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Renée Zellweger</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robin Williams</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Comedy            0  1  All\n",
       "actor1                     \n",
       "Adam Sandler      0  4    4\n",
       "Chevy Chase       0  4    4\n",
       "Bill Murray       0  3    3\n",
       "Eddie Murphy      0  3    3\n",
       "Jack Black        0  3    3\n",
       "Jim Carrey        0  3    3\n",
       "Johnny Knoxville  0  3    3\n",
       "Mike Myers        0  3    3\n",
       "Renée Zellweger   0  3    3\n",
       "Robin Williams    0  3    3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test (only in train data) if actors are predictive of genre, example comedy\n",
    "subset =pd.crosstab(X_train01.actor1,Y_train01[\"Comedy\"], margins = True)\n",
    "subset.pred = np.where(((subset.All - subset.iloc[:,1] == 0) & (subset.All>2)), 1,0)\n",
    "subset[subset.pred ==1].sort_values(by=['All'], ascending=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our performance metrics\n",
    "In a multi-class prediction problem, evaluating the performance of a model is more straightforward as classes are, by definition, mutually exclusive. Our movie genre classification problem is, by nature, a multi-label problem: genres are not mutually exclusive and having more than one genre label per movie is very frequent. Evaluating the performance of such models is an hard task by itself, but the scientific literature has prior research that can be used as a reference.\n",
    "\n",
    "Let $E=\\{[0, 1], [1, 1]\\}$ be the set of 2 expected labels for 2 samples and $P=\\{[0, 0], [0, 0]\\}$ the set of predicted labels. Here’s how the scoring would look with the following metrics:\n",
    "\n",
    "* **Subset accuracy** - the ratio of samples with a set of predicted labels exactly matching the corresponding set of expected labels.\n",
    "  The subset accuracy, in this case, would score 0, as there’s no full overlap for the labels in each sample. Predicting $P=\\{[0, 1], [0, 0]\\}$ would, instead, produce a score of 0.5. It’s important to note how this performance metric heavily penalizes partial label matching and provides a lower accuracy score compared to other metrics. This is implemented by the [sklearn.metrics.accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn-metrics-accuracy-score) function.\n",
    "* **Hamming loss** - the average relevance of a sample to a set of labels. This is computed by averaging the number of misclassified labels on all the samples. This value should ideally be 0 for perfect predictions, but in general the lower is this value, the better. In the provided example, the hamming loss would be 0.75. This is implemented by the [sklearn.metrics.hamming_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html#sklearn-metrics-hamming-loss) function.\n",
    "* **Zero-one loss** - This the complement of the subset accuracy described above. This is implemented by the [sklearn.metrics.zero_one_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html#sklearn-metrics-zero-one-loss) function.\n",
    "* **Jaccard similarity** - this metric measure the average overlapping of the predicted labels and the expected labels for each sample. The overlapping of the label set is defined as the intersection of the predicted labels and the expected labels divided by the size of the union of the two sets. This is implemented by the [sklearn.metrics.jaccard_similarity_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_similarity_score.html#sklearn-metrics-jaccard-similarity-score) function.\n",
    "* **Average per-genre accuracy** - This is the average number of times. We provided our own implementation for this metric in this notebook.\n",
    "* **Precision** - Is the average ratio of predicted correct labels to the total number of labels. This is reported by the [sklearn.metrics.classification_report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) function.\n",
    "* **Recall** - Is the average ratio of predicted correct labels to the number of expected labels. This is reported by the [sklearn.metrics.classification_report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) function.\n",
    "* **F1** - The F1 score is the harmonic mean of the precision and recall: the closer this value is to 1.0, the better is the predicted set of labels. This is reported  by the [sklearn.metrics.classification_report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) function.\n",
    "\n",
    "The utility function below produces a summary of all the above performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detailed_report(predicted_y, test_y):\n",
    "    print classification_report(test_y, predicted_y,\n",
    "                                target_names = label_binarizer.classes_)\n",
    "    \n",
    "    print(\"\\n**** Per genre accuracy ****\\n\\n\")\n",
    "\n",
    "    per_genre_accuracies = []\n",
    "    for i, label in enumerate(label_binarizer.classes_):\n",
    "        per_genre_accuracies.append(accuracy_score(predicted_y[:, i], test_y[:,i]))\n",
    "        print(\"{} accuracy:\\t{:.3f}\".format(label, per_genre_accuracies[-1]))\n",
    "\n",
    "    print(\"\\n**** OTHER METRICS ****\\n\\n\")\n",
    "    print(\"Overall accuracy:\\t{:.3f}\".format(accuracy_score(test_y, predicted_y)))\n",
    "    print(\"Average per-genre accuracy:\\t{:.3f}\".format(np.mean(per_genre_accuracies)))\n",
    "    print(\"Hamming loss:\\t\\t{:.3f}\".format(hamming_loss(test_y, predicted_y)))\n",
    "    print(\"Zero one loss:\\t\\t{:.3f}\".format(zero_one_loss(test_y, predicted_y)))\n",
    "    print(\"Jaccard similarity:\\t{:.3f}\".format(jaccard_similarity_score(test_y, predicted_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a naive models that randomly assigns genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8762L, 20L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_test01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_using_freqs(y):\n",
    "    #assinging randomly a label to each of the genres\n",
    "    rngenre = np.array(range( len(y)))\n",
    "    np.random.seed(42)\n",
    "    for i in range(y.shape[1]):\n",
    "        rngenre_i = np.random.binomial(1, y[:,i].sum()*1.0/len(y), size=len(y))\n",
    "        rngenre = np.vstack((rngenre, rngenre_i))\n",
    "\n",
    "    rngenre = rngenre[1:rngenre.shape[1],:]\n",
    "\n",
    "    random_genre = rngenre.reshape(rngenre.shape[1],rngenre.shape[0])\n",
    "    return random_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1_test01random = random_using_freqs(y1_test01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a detailed report for a model returning random labels for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.28      0.15      0.20      2088\n",
      "      Adventure       0.16      0.13      0.14      1299\n",
      "      Animation       0.07      0.13      0.09       568\n",
      "         Comedy       0.31      0.12      0.17      2851\n",
      "          Crime       0.15      0.13      0.14      1190\n",
      "    Documentary       0.01      0.11      0.02       128\n",
      "          Drama       0.50      0.13      0.20      4213\n",
      "         Family       0.10      0.12      0.11       826\n",
      "        Fantasy       0.09      0.12      0.10       754\n",
      "        Foreign       0.00      0.03      0.00        30\n",
      "        History       0.04      0.12      0.06       312\n",
      "         Horror       0.12      0.12      0.12      1038\n",
      "          Music       0.02      0.12      0.04       230\n",
      "        Mystery       0.07      0.12      0.09       633\n",
      "        Romance       0.16      0.12      0.14      1489\n",
      "Science Fiction       0.12      0.14      0.13       908\n",
      "       TV Movie       0.01      0.10      0.02        89\n",
      "       Thriller       0.26      0.12      0.16      2374\n",
      "            War       0.03      0.11      0.05       273\n",
      "        Western       0.02      0.15      0.04       168\n",
      "\n",
      "    avg / total       0.25      0.13      0.15     21461\n",
      "\n",
      "\n",
      "**** Per genre accuracy ****\n",
      "\n",
      "\n",
      "Action accuracy:\t0.708\n",
      "Adventure accuracy:\t0.771\n",
      "Animation accuracy:\t0.831\n",
      "Comedy accuracy:\t0.628\n",
      "Crime accuracy:\t0.778\n",
      "Documentary accuracy:\t0.866\n",
      "Drama accuracy:\t0.519\n",
      "Family accuracy:\t0.810\n",
      "Fantasy accuracy:\t0.813\n",
      "Foreign accuracy:\t0.875\n",
      "History accuracy:\t0.853\n",
      "Horror accuracy:\t0.789\n",
      "Music accuracy:\t0.855\n",
      "Mystery accuracy:\t0.825\n",
      "Romance accuracy:\t0.747\n",
      "Science Fiction accuracy:\t0.802\n",
      "TV Movie accuracy:\t0.873\n",
      "Thriller accuracy:\t0.672\n",
      "War accuracy:\t0.860\n",
      "Western accuracy:\t0.867\n",
      "\n",
      "**** OTHER METRICS ****\n",
      "\n",
      "\n",
      "Overall accuracy:\t0.004\n",
      "Average per-genre accuracy:\t0.787\n",
      "Hamming loss:\t\t0.213\n",
      "Zero one loss:\t\t0.996\n",
      "Jaccard similarity:\t0.058\n"
     ]
    }
   ],
   "source": [
    "detailed_report(y1_test01random, y1_test01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a detailed report for a model always assigning the same labels for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.00      0.00      0.00      2088\n",
      "      Adventure       0.00      0.00      0.00      1299\n",
      "      Animation       0.00      0.00      0.00       568\n",
      "         Comedy       0.00      0.00      0.00      2851\n",
      "          Crime       0.00      0.00      0.00      1190\n",
      "    Documentary       0.00      0.00      0.00       128\n",
      "          Drama       0.00      0.00      0.00      4213\n",
      "         Family       0.00      0.00      0.00       826\n",
      "        Fantasy       0.00      0.00      0.00       754\n",
      "        Foreign       0.00      0.00      0.00        30\n",
      "        History       0.00      0.00      0.00       312\n",
      "         Horror       0.00      0.00      0.00      1038\n",
      "          Music       0.00      0.00      0.00       230\n",
      "        Mystery       0.00      0.00      0.00       633\n",
      "        Romance       0.00      0.00      0.00      1489\n",
      "Science Fiction       0.00      0.00      0.00       908\n",
      "       TV Movie       0.00      0.00      0.00        89\n",
      "       Thriller       0.00      0.00      0.00      2374\n",
      "            War       0.00      0.00      0.00       273\n",
      "        Western       0.00      0.00      0.00       168\n",
      "\n",
      "    avg / total       0.00      0.00      0.00     21461\n",
      "\n",
      "\n",
      "**** Per genre accuracy ****\n",
      "\n",
      "\n",
      "Action accuracy:\t0.762\n",
      "Adventure accuracy:\t0.852\n",
      "Animation accuracy:\t0.935\n",
      "Comedy accuracy:\t0.675\n",
      "Crime accuracy:\t0.864\n",
      "Documentary accuracy:\t0.985\n",
      "Drama accuracy:\t0.519\n",
      "Family accuracy:\t0.906\n",
      "Fantasy accuracy:\t0.914\n",
      "Foreign accuracy:\t0.997\n",
      "History accuracy:\t0.964\n",
      "Horror accuracy:\t0.882\n",
      "Music accuracy:\t0.974\n",
      "Mystery accuracy:\t0.928\n",
      "Romance accuracy:\t0.830\n",
      "Science Fiction accuracy:\t0.896\n",
      "TV Movie accuracy:\t0.990\n",
      "Thriller accuracy:\t0.729\n",
      "War accuracy:\t0.969\n",
      "Western accuracy:\t0.981\n",
      "\n",
      "**** OTHER METRICS ****\n",
      "\n",
      "\n",
      "Overall accuracy:\t0.006\n",
      "Average per-genre accuracy:\t0.878\n",
      "Hamming loss:\t\t0.122\n",
      "Zero one loss:\t\t0.994\n",
      "Jaccard similarity:\t0.006\n"
     ]
    }
   ],
   "source": [
    "detailed_report(np.zeros(y1_test01.shape), y1_test01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (training on 10%  of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_svc(xtrain, ytrain, xtest, ytest, ytest_random):\n",
    "    model_to_set = OneVsRestClassifier(SVC(kernel=\"linear\"), n_jobs=-1)\n",
    "\n",
    "    tuned_parameters = [\n",
    "      {'estimator__C': [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 50.0], 'estimator__kernel': ['linear']},\n",
    "      {'estimator__C': [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 50.0],\n",
    "       'estimator__gamma':  [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 0.2, 0.3],\n",
    "       'estimator__kernel': ['rbf']\n",
    "      },\n",
    "     ]\n",
    "\n",
    "\n",
    "    scores = ['precision']\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(model_to_set, \n",
    "                           param_grid = tuned_parameters, cv=5,\n",
    "                           scoring='%s_macro' % score,\n",
    "                          verbose = 5)\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        \n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "        print(\"Detailed classification report:\")\n",
    "        \n",
    "        y_test_predict = clf.predict(xtest)\n",
    "        \n",
    "        detailed_report(y_test_predict, ytest)\n",
    "        print(\"\\n**** compare this result with random labeling ****\\n\\n\")\n",
    "\n",
    "        print classification_report(ytest,  ytest_random, target_names =label_binarizer.classes_)\n",
    "        print ()\n",
    "\n",
    "    return clf.best_params_, classification_report(ytest,  y_test_predict), y_test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words from keywords, tagline, overview plus actors and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "()\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "[CV] estimator__kernel=linear, estimator__C=1.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=1.0, score=0.323473, total=   2.1s\n",
      "[CV] estimator__kernel=linear, estimator__C=1.0 ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__kernel=linear, estimator__C=1.0, score=0.358270, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=1.0 ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__kernel=linear, estimator__C=1.0, score=0.241367, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=1.0 ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__kernel=linear, estimator__C=1.0, score=0.282172, total=   2.1s\n",
      "[CV] estimator__kernel=linear, estimator__C=1.0 ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__kernel=linear, estimator__C=1.0, score=0.263081, total=   2.1s\n",
      "[CV] estimator__kernel=linear, estimator__C=2.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=2.0, score=0.323473, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=2.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=2.0, score=0.358270, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=2.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=2.0, score=0.241367, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=2.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=2.0, score=0.282172, total=   2.1s\n",
      "[CV] estimator__kernel=linear, estimator__C=2.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=2.0, score=0.263081, total=   2.2s\n",
      "[CV] estimator__kernel=linear, estimator__C=4.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=4.0, score=0.323473, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=4.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=4.0, score=0.358270, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=4.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=4.0, score=0.241367, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=4.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=4.0, score=0.282172, total=   2.1s\n",
      "[CV] estimator__kernel=linear, estimator__C=4.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=4.0, score=0.263081, total=   2.2s\n",
      "[CV] estimator__kernel=linear, estimator__C=8.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=8.0, score=0.323473, total=   2.2s\n",
      "[CV] estimator__kernel=linear, estimator__C=8.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=8.0, score=0.358270, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=8.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=8.0, score=0.241367, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=8.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=8.0, score=0.282172, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=8.0 ......................\n",
      "[CV]  estimator__kernel=linear, estimator__C=8.0, score=0.263081, total=   2.3s\n",
      "[CV] estimator__kernel=linear, estimator__C=16.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=16.0, score=0.323473, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=16.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=16.0, score=0.358270, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=16.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=16.0, score=0.241367, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=16.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=16.0, score=0.282172, total=   2.1s\n",
      "[CV] estimator__kernel=linear, estimator__C=16.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=16.0, score=0.263081, total=   2.2s\n",
      "[CV] estimator__kernel=linear, estimator__C=32.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=32.0, score=0.323473, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=32.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=32.0, score=0.358270, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=32.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=32.0, score=0.241367, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=32.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=32.0, score=0.282172, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=32.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=32.0, score=0.263081, total=   2.2s\n",
      "[CV] estimator__kernel=linear, estimator__C=50.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=50.0, score=0.323473, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=50.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=50.0, score=0.358270, total=   1.9s\n",
      "[CV] estimator__kernel=linear, estimator__C=50.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=50.0, score=0.241367, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=50.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=50.0, score=0.282172, total=   2.0s\n",
      "[CV] estimator__kernel=linear, estimator__C=50.0 .....................\n",
      "[CV]  estimator__kernel=linear, estimator__C=50.0, score=0.263081, total=   2.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001, score=0.050000, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001, score=0.021579, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001, score=0.000000, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001, score=0.050000, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0001, score=0.000000, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005, score=0.244540, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005, score=0.258077, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005, score=0.246373, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005, score=0.484368, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.0005, score=0.321019, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001, score=0.242792, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001, score=0.323403, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001, score=0.234263, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001, score=0.462968, total=   2.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.001, score=0.254182, total=   2.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005, score=0.035937, total=   3.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005, score=0.021591, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005, score=0.029545, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005, score=0.050000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.005, score=0.043750, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01, score=0.025000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01, score=0.019697, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01, score=0.050000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.01, score=0.050000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1, score=0.050000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1, score=0.013592, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.1, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2, score=0.000000, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2, score=0.013592, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3, score=0.013592, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=1.0, estimator__gamma=0.3, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001, score=0.149783, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001, score=0.124576, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001, score=0.129630, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001, score=0.347727, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0001, score=0.071154, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005, score=0.375738, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005, score=0.502089, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005, score=0.472625, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005, score=0.476621, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.0005, score=0.334128, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001, score=0.352669, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001, score=0.503831, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001, score=0.498604, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001, score=0.465703, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.001, score=0.369598, total=   2.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005, score=0.117029, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005, score=0.103571, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005, score=0.055303, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005, score=0.072826, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.005, score=0.116667, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01, score=0.050000, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01, score=0.017742, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01, score=0.033333, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01, score=0.050000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.01, score=0.050000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1, score=0.050000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1, score=0.013592, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1, score=0.050000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.1, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2, score=0.013592, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2, score=0.000000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.2, score=0.000000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3, score=0.000000, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3, score=0.013592, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=2.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001, score=0.248584, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001, score=0.421769, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001, score=0.367720, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001, score=0.505897, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0001, score=0.318407, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005, score=0.325474, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005, score=0.496214, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005, score=0.383838, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005, score=0.431447, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.0005, score=0.376359, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001, score=0.385125, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001, score=0.490724, total=   2.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001, score=0.371370, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001, score=0.467111, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.001, score=0.372838, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005, score=0.141667, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005, score=0.101429, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005, score=0.086275, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005, score=0.120833, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.005, score=0.091667, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01, score=0.048810, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01, score=0.017742, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01, score=0.025000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01, score=0.037500, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.01, score=0.050000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1, score=0.050000, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1, score=0.013592, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1, score=0.000000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1, score=0.050000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.1, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2, score=0.013592, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.2, score=0.000000, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3, score=0.000000, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3, score=0.013592, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=4.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001, score=0.364827, total=   2.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001, score=0.529244, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001, score=0.485616, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001, score=0.433535, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0001, score=0.308475, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005, score=0.383205, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005, score=0.419961, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005, score=0.342190, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005, score=0.387281, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.0005, score=0.366847, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001, score=0.400505, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001, score=0.444153, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001, score=0.349124, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001, score=0.427832, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.001, score=0.389798, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005, score=0.140686, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005, score=0.157500, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005, score=0.076471, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005, score=0.185667, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.005, score=0.083333, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01, score=0.048810, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01, score=0.017742, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01, score=0.016667, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01, score=0.037500, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.01, score=0.050000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1, score=0.050000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1, score=0.013592, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1, score=0.050000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.1, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2, score=0.013592, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3, score=0.013592, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3 ...\n",
      "[CV]  estimator__kernel=rbf, estimator__C=8.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001, score=0.401205, total=   2.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001, score=0.439463, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001, score=0.368817, total=   2.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001, score=0.402137, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0001, score=0.335045, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005, score=0.344183, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005, score=0.401270, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005, score=0.319460, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005, score=0.356457, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.0005, score=0.314590, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001, score=0.328707, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001, score=0.441066, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001, score=0.316338, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001, score=0.396535, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.001, score=0.385082, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005, score=0.139465, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005, score=0.159722, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005, score=0.075000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005, score=0.185417, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.005, score=0.083333, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01, score=0.048810, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01, score=0.017742, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01, score=0.016667, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01, score=0.037500, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.01, score=0.050000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1, score=0.050000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1, score=0.013592, total=   4.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1, score=0.000000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1, score=0.050000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.1, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2, score=0.000000, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2, score=0.013592, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3, score=0.013592, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=16.0, estimator__gamma=0.3, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001, score=0.373288, total=   2.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001, score=0.390079, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001, score=0.319961, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001, score=0.353322, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0001, score=0.336782, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005, score=0.300579, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005, score=0.376459, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005, score=0.292687, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005, score=0.342765, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.0005, score=0.304271, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001, score=0.311550, total=   2.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001, score=0.425811, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001, score=0.294905, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001, score=0.386433, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.001, score=0.314766, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005, score=0.139465, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005, score=0.158611, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005, score=0.076316, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005, score=0.185145, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.005, score=0.083333, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01, score=0.048810, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01, score=0.017742, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01, score=0.016667, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01, score=0.037500, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.01, score=0.050000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1, score=0.050000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1, score=0.013592, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1, score=0.050000, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.1, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2, score=0.013592, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3, score=0.000000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3, score=0.013592, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3, score=0.000000, total=   4.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3, score=0.000000, total=   4.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=32.0, estimator__gamma=0.3, score=0.000000, total=   4.5s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001, score=0.380586, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001, score=0.372527, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001, score=0.299107, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001, score=0.337319, total=   2.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0001, score=0.338173, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005, score=0.294663, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005, score=0.369788, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005, score=0.290818, total=   2.3s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005, score=0.341889, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.0005, score=0.300043, total=   2.4s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001, score=0.313765, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001, score=0.423016, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001, score=0.294666, total=   2.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001, score=0.385751, total=   2.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.001, score=0.314889, total=   2.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005, score=0.139465, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005, score=0.158611, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005, score=0.076316, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005, score=0.185145, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005 \n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.005, score=0.083333, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01, score=0.048810, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01, score=0.017742, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01, score=0.016667, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01, score=0.037500, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01 .\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.01, score=0.050000, total=   3.7s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1, score=0.050000, total=   3.6s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1, score=0.013592, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1, score=0.000000, total=   3.9s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1, score=0.050000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.1, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2, score=0.013592, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2, score=0.000000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.2, score=0.000000, total=   4.0s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3, score=0.000000, total=   4.2s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3, score=0.013592, total=   4.1s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3, score=0.000000, total=   3.8s\n",
      "[CV] estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3 ..\n",
      "[CV]  estimator__kernel=rbf, estimator__C=50.0, estimator__gamma=0.3, score=0.000000, total=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 315 out of 315 | elapsed: 44.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.001}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.294 (+/-0.084) for {'estimator__kernel': 'linear', 'estimator__C': 1.0}\n",
      "0.294 (+/-0.084) for {'estimator__kernel': 'linear', 'estimator__C': 2.0}\n",
      "0.294 (+/-0.084) for {'estimator__kernel': 'linear', 'estimator__C': 4.0}\n",
      "0.294 (+/-0.084) for {'estimator__kernel': 'linear', 'estimator__C': 8.0}\n",
      "0.294 (+/-0.084) for {'estimator__kernel': 'linear', 'estimator__C': 16.0}\n",
      "0.294 (+/-0.084) for {'estimator__kernel': 'linear', 'estimator__C': 32.0}\n",
      "0.294 (+/-0.084) for {'estimator__kernel': 'linear', 'estimator__C': 50.0}\n",
      "0.024 (+/-0.045) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.0001}\n",
      "0.311 (+/-0.182) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.0005}\n",
      "0.303 (+/-0.171) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.001}\n",
      "0.036 (+/-0.020) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.005}\n",
      "0.029 (+/-0.038) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.01}\n",
      "0.013 (+/-0.039) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.1}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.2}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 1.0, 'estimator__gamma': 0.3}\n",
      "0.164 (+/-0.190) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.0001}\n",
      "0.432 (+/-0.130) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.0005}\n",
      "0.438 (+/-0.129) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.001}\n",
      "0.093 (+/-0.050) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.005}\n",
      "0.040 (+/-0.026) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.01}\n",
      "0.023 (+/-0.046) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.1}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.2}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 2.0, 'estimator__gamma': 0.3}\n",
      "0.372 (+/-0.176) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.0001}\n",
      "0.403 (+/-0.115) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.0005}\n",
      "0.417 (+/-0.102) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.001}\n",
      "0.108 (+/-0.041) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.005}\n",
      "0.036 (+/-0.026) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.01}\n",
      "0.023 (+/-0.046) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.1}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.2}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 4.0, 'estimator__gamma': 0.3}\n",
      "0.424 (+/-0.160) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.0001}\n",
      "0.380 (+/-0.051) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.0005}\n",
      "0.402 (+/-0.066) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.001}\n",
      "0.129 (+/-0.085) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.005}\n",
      "0.034 (+/-0.029) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.01}\n",
      "0.023 (+/-0.046) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.1}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.2}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 8.0, 'estimator__gamma': 0.3}\n",
      "0.389 (+/-0.070) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.0001}\n",
      "0.347 (+/-0.062) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.0005}\n",
      "0.374 (+/-0.092) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.001}\n",
      "0.129 (+/-0.086) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.005}\n",
      "0.034 (+/-0.029) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.01}\n",
      "0.023 (+/-0.046) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.1}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.2}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 16.0, 'estimator__gamma': 0.3}\n",
      "0.355 (+/-0.050) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.0001}\n",
      "0.323 (+/-0.063) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.0005}\n",
      "0.347 (+/-0.101) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.001}\n",
      "0.129 (+/-0.085) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.005}\n",
      "0.034 (+/-0.029) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.01}\n",
      "0.023 (+/-0.046) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.1}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.2}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 32.0, 'estimator__gamma': 0.3}\n",
      "0.346 (+/-0.058) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.0001}\n",
      "0.319 (+/-0.062) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.0005}\n",
      "0.346 (+/-0.099) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.001}\n",
      "0.129 (+/-0.085) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.005}\n",
      "0.034 (+/-0.029) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.01}\n",
      "0.023 (+/-0.046) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.1}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.2}\n",
      "0.003 (+/-0.011) for {'estimator__kernel': 'rbf', 'estimator__C': 50.0, 'estimator__gamma': 0.3}\n",
      "()\n",
      "Detailed classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.65      0.37      0.47      2088\n",
      "      Adventure       0.56      0.21      0.31      1299\n",
      "      Animation       0.60      0.19      0.29       568\n",
      "         Comedy       0.65      0.41      0.50      2851\n",
      "          Crime       0.63      0.28      0.39      1190\n",
      "    Documentary       0.00      0.00      0.00       128\n",
      "          Drama       0.67      0.61      0.64      4213\n",
      "         Family       0.66      0.21      0.31       826\n",
      "        Fantasy       0.56      0.13      0.21       754\n",
      "        Foreign       0.00      0.00      0.00        30\n",
      "        History       0.50      0.01      0.01       312\n",
      "         Horror       0.82      0.24      0.37      1038\n",
      "          Music       0.69      0.14      0.24       230\n",
      "        Mystery       0.49      0.09      0.15       633\n",
      "        Romance       0.59      0.33      0.42      1489\n",
      "Science Fiction       0.78      0.35      0.48       908\n",
      "       TV Movie       0.00      0.00      0.00        89\n",
      "       Thriller       0.61      0.34      0.44      2374\n",
      "            War       0.77      0.25      0.38       273\n",
      "        Western       1.00      0.01      0.02       168\n",
      "\n",
      "    avg / total       0.64      0.35      0.43     21461\n",
      "\n",
      "\n",
      "**** Per genre accuracy ****\n",
      "\n",
      "\n",
      "Action accuracy:\t0.802\n",
      "Adventure accuracy:\t0.859\n",
      "Animation accuracy:\t0.939\n",
      "Comedy accuracy:\t0.737\n",
      "Crime accuracy:\t0.880\n",
      "Documentary accuracy:\t0.985\n",
      "Drama accuracy:\t0.669\n",
      "Family accuracy:\t0.915\n",
      "Fantasy accuracy:\t0.916\n",
      "Foreign accuracy:\t0.997\n",
      "History accuracy:\t0.964\n",
      "Horror accuracy:\t0.904\n",
      "Music accuracy:\t0.976\n",
      "Mystery accuracy:\t0.928\n",
      "Romance accuracy:\t0.847\n",
      "Science Fiction accuracy:\t0.923\n",
      "TV Movie accuracy:\t0.990\n",
      "Thriller accuracy:\t0.763\n",
      "War accuracy:\t0.974\n",
      "Western accuracy:\t0.981\n",
      "\n",
      "**** OTHER METRICS ****\n",
      "\n",
      "\n",
      "Overall accuracy:\t0.113\n",
      "Average per-genre accuracy:\t0.897\n",
      "Hamming loss:\t\t0.103\n",
      "Zero one loss:\t\t0.887\n",
      "Jaccard similarity:\t0.331\n",
      "\n",
      "**** compare this result with random labeling ****\n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.28      0.15      0.20      2088\n",
      "      Adventure       0.16      0.13      0.14      1299\n",
      "      Animation       0.07      0.13      0.09       568\n",
      "         Comedy       0.31      0.12      0.17      2851\n",
      "          Crime       0.15      0.13      0.14      1190\n",
      "    Documentary       0.01      0.11      0.02       128\n",
      "          Drama       0.50      0.13      0.20      4213\n",
      "         Family       0.10      0.12      0.11       826\n",
      "        Fantasy       0.09      0.12      0.10       754\n",
      "        Foreign       0.00      0.03      0.00        30\n",
      "        History       0.04      0.12      0.06       312\n",
      "         Horror       0.12      0.12      0.12      1038\n",
      "          Music       0.02      0.12      0.04       230\n",
      "        Mystery       0.07      0.12      0.09       633\n",
      "        Romance       0.16      0.12      0.14      1489\n",
      "Science Fiction       0.12      0.14      0.13       908\n",
      "       TV Movie       0.01      0.10      0.02        89\n",
      "       Thriller       0.26      0.12      0.16      2374\n",
      "            War       0.03      0.11      0.05       273\n",
      "        Western       0.02      0.15      0.04       168\n",
      "\n",
      "    avg / total       0.25      0.13      0.15     21461\n",
      "\n",
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alessio\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "std_scale = StandardScaler().fit(np.array(X_train01.iloc[:,:-2]))\n",
    "X_train_std = std_scale.transform(np.array(X_train01.iloc[:,:-2]))\n",
    "X_test_std = std_scale.transform(np.array(X_test01.iloc[:,:-2]))\n",
    "\n",
    "param_01b, class_report_01b, y_test_pred_01b =\\\n",
    "    tune_svc(X_train_std, y1_train01, X_test_std, y1_test01, y1_test01random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation\n",
    "On a first look, the best-tuned SVM model using poster metadata, didn't have an impressive performance with a *precision* of $0.64$, a recall of $0.35$ and a F1 score of $0.43$, on average. However, as we can see from the per-genre report, the precision and recall are very dependant on the considered genre: *Drama*, also being the dominant genre, has the highest values for all these metrics while *TV Movie* performs the worst, together with *Foreign*. This is dragging down our model, suggesting that we could potentially suppress or aggregate these genres to improve the performances.\n",
    "\n",
    "It's interesting to note how the value for the *hamming loss*, which is as low as $0.103$, half of the loss compared to the *naive random classifier* and slightly lower than the naive classifier always assigning the same label.\n",
    "\n",
    "The *jaccard similarity score* gives a better highlight of the performance of this classifier compared to the other, dominating the ranking with a score of $0.331$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def tune_rf(xtrain, ytrain, xtest, ytest, ytest_random):\n",
    "    # Set the parameters by cross-validation\n",
    "    model_to_set = OneVsRestClassifier(RandomForestClassifier(random_state=0), n_jobs=-1)\n",
    "    tuned_parameters = [\n",
    "      {\"estimator__max_depth\": [10,12,14,16,18,20,22], 'estimator__n_estimators': [ 100,150,200, 500]}\n",
    "    ]\n",
    "\n",
    "    scores = ['precision']\n",
    "    \n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(model_to_set, \n",
    "                           param_grid = tuned_parameters, cv=5,\n",
    "                           scoring='%s_macro' % score, verbose = 5)\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        \n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "        print(\"Detailed classification report:\")\n",
    "        \n",
    "        y_test_predict = clf.predict(xtest)\n",
    "        \n",
    "        detailed_report(y_test_predict, ytest)\n",
    "        print(\"\\n**** compare this result with random labeling ****\\n\\n\")\n",
    "\n",
    "        print classification_report(ytest,  ytest_random, target_names =label_binarizer.classes_)\n",
    "        print ()\n",
    "   \n",
    "    return clf.best_params_, classification_report(ytest,  y_test_predict), y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All, sampling 0.1 of all, normalized\n",
      "# Tuning hyper-parameters for precision\n",
      "()\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=100, score=0.329840, total=   3.1s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=100 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__max_depth=10, estimator__n_estimators=100, score=0.408278, total=   3.4s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=100 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__max_depth=10, estimator__n_estimators=100, score=0.428671, total=   3.4s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=100 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__max_depth=10, estimator__n_estimators=100, score=0.431354, total=   3.3s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=100 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__max_depth=10, estimator__n_estimators=100, score=0.305894, total=   3.3s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=150, score=0.270170, total=   4.3s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=150, score=0.432100, total=   4.6s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=150, score=0.429072, total=   4.6s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=150, score=0.473016, total=   4.7s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=150, score=0.361818, total=   4.5s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=200, score=0.324107, total=   5.6s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=200, score=0.430079, total=   6.0s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=200, score=0.403795, total=   6.2s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=200, score=0.482892, total=   6.1s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=200, score=0.361349, total=   6.1s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=500, score=0.309236, total=  13.4s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=500, score=0.433135, total=  14.4s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=500, score=0.414448, total=  15.0s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=500, score=0.433057, total=  14.5s\n",
      "[CV] estimator__max_depth=10, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=10, estimator__n_estimators=500, score=0.365577, total=  13.7s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=100, score=0.295011, total=   3.4s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=100, score=0.420982, total=   3.5s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=100, score=0.446210, total=   3.5s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=100, score=0.509257, total=   3.4s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=100, score=0.307424, total=   3.5s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=150, score=0.262024, total=   4.6s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=150, score=0.410851, total=   4.8s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=150, score=0.417794, total=   5.0s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=150, score=0.472339, total=   4.8s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=150, score=0.363974, total=   4.7s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=200, score=0.258209, total=   5.8s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=200, score=0.408246, total=   6.2s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=200, score=0.447113, total=   6.0s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=200, score=0.470684, total=   6.2s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=200, score=0.362570, total=   6.3s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=500, score=0.310324, total=  14.0s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=500, score=0.423030, total=  14.7s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=500, score=0.405147, total=  14.5s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=500, score=0.473363, total=  14.7s\n",
      "[CV] estimator__max_depth=12, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=12, estimator__n_estimators=500, score=0.367512, total=  14.8s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=100, score=0.346339, total=   3.4s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=100, score=0.370181, total=   3.4s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=100, score=0.435902, total=   3.3s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=100, score=0.512219, total=   3.3s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=100, score=0.360042, total=   3.4s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=150, score=0.361444, total=   4.5s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=150, score=0.368494, total=   5.0s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=150, score=0.388318, total=   4.9s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=150, score=0.507045, total=   4.8s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=150, score=0.365029, total=   4.9s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=200, score=0.258343, total=   5.9s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=200, score=0.362140, total=   6.3s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=200, score=0.450033, total=   6.2s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=200, score=0.523205, total=   6.2s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=200, score=0.360635, total=   6.2s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=500, score=0.315545, total=  13.3s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=500, score=0.381061, total=  14.3s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=500, score=0.392143, total=  14.7s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=500, score=0.522927, total=  14.4s\n",
      "[CV] estimator__max_depth=14, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=14, estimator__n_estimators=500, score=0.362333, total=  14.4s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=100, score=0.291368, total=   3.2s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=100, score=0.387653, total=   3.5s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=100, score=0.459244, total=   3.5s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=100, score=0.496885, total=   3.6s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=100, score=0.432821, total=   3.5s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=150, score=0.299471, total=   4.6s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=150, score=0.375051, total=   4.9s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=150, score=0.410143, total=   4.8s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=150, score=0.476761, total=   4.9s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=150, score=0.452456, total=   5.1s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=200, score=0.298973, total=   6.0s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=200, score=0.379941, total=   6.3s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=200, score=0.460857, total=   6.3s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=200, score=0.515501, total=   6.3s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=200, score=0.400625, total=   6.2s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=500, score=0.361225, total=  14.0s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=500, score=0.406794, total=  15.0s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=500, score=0.446420, total=  15.1s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=500, score=0.520628, total=  14.6s\n",
      "[CV] estimator__max_depth=16, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=16, estimator__n_estimators=500, score=0.421429, total=  15.1s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=100, score=0.343379, total=   3.3s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=100, score=0.411834, total=   3.8s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=100, score=0.469503, total=   3.6s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=100, score=0.492778, total=   3.7s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=100, score=0.460082, total=   3.5s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=150, score=0.358021, total=   4.7s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=150, score=0.375012, total=   4.9s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=150, score=0.465833, total=   5.2s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=150, score=0.497112, total=   5.4s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=150, score=0.432764, total=   5.0s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=200, score=0.377700, total=   6.1s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=200, score=0.369263, total=   6.4s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=200, score=0.471624, total=   6.5s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=200, score=0.489814, total=   6.7s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=200, score=0.417106, total=   6.2s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=500, score=0.336786, total=  14.1s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=500, score=0.380797, total=  15.4s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=500, score=0.483015, total=  15.0s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=500, score=0.488308, total=  14.7s\n",
      "[CV] estimator__max_depth=18, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=18, estimator__n_estimators=500, score=0.413774, total=  15.1s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=100, score=0.344524, total=   3.4s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=100, score=0.410704, total=   3.6s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=100, score=0.464284, total=   3.7s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=100, score=0.479815, total=   3.7s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=100, score=0.466443, total=   3.7s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=150, score=0.339014, total=   4.7s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=150, score=0.372046, total=   4.9s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=150, score=0.463297, total=   5.1s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=150, score=0.486023, total=   5.2s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=150, score=0.417530, total=   5.1s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=200, score=0.339217, total=   6.0s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=200, score=0.378632, total=   6.3s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=200, score=0.470848, total=   6.4s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=200, score=0.481209, total=   6.5s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=200, score=0.402472, total=   6.4s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=500, score=0.332155, total=  13.9s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=500, score=0.388023, total=  15.0s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=500, score=0.475287, total=  15.9s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=500, score=0.493375, total=  15.4s\n",
      "[CV] estimator__max_depth=20, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=20, estimator__n_estimators=500, score=0.418707, total=  16.5s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=100, score=0.340773, total=   3.6s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=100, score=0.440737, total=   3.7s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=100, score=0.470479, total=   3.7s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=100, score=0.469791, total=   3.7s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=100 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=100, score=0.466966, total=   3.7s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=150, score=0.341460, total=   5.0s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=150, score=0.387880, total=   5.3s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=150, score=0.450057, total=   5.4s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=150, score=0.459532, total=   5.2s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=150 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=150, score=0.418396, total=   5.3s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=200, score=0.340467, total=   6.3s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=200, score=0.388935, total=   6.7s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=200, score=0.459609, total=   6.8s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=200, score=0.467528, total=   6.8s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=200 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=200, score=0.413521, total=   6.5s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=500, score=0.332816, total=  16.0s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=500, score=0.372459, total=  16.5s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=500, score=0.409458, total=  15.7s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=500, score=0.509635, total=  16.0s\n",
      "[CV] estimator__max_depth=22, estimator__n_estimators=500 ............\n",
      "[CV]  estimator__max_depth=22, estimator__n_estimators=500, score=0.402587, total=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 140 out of 140 | elapsed: 23.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'estimator__max_depth': 22, 'estimator__n_estimators': 100}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.381 (+/-0.105) for {'estimator__max_depth': 10, 'estimator__n_estimators': 100}\n",
      "0.393 (+/-0.142) for {'estimator__max_depth': 10, 'estimator__n_estimators': 150}\n",
      "0.400 (+/-0.110) for {'estimator__max_depth': 10, 'estimator__n_estimators': 200}\n",
      "0.391 (+/-0.096) for {'estimator__max_depth': 10, 'estimator__n_estimators': 500}\n",
      "0.396 (+/-0.165) for {'estimator__max_depth': 12, 'estimator__n_estimators': 100}\n",
      "0.385 (+/-0.141) for {'estimator__max_depth': 12, 'estimator__n_estimators': 150}\n",
      "0.389 (+/-0.150) for {'estimator__max_depth': 12, 'estimator__n_estimators': 200}\n",
      "0.396 (+/-0.109) for {'estimator__max_depth': 12, 'estimator__n_estimators': 500}\n",
      "0.405 (+/-0.124) for {'estimator__max_depth': 14, 'estimator__n_estimators': 100}\n",
      "0.398 (+/-0.110) for {'estimator__max_depth': 14, 'estimator__n_estimators': 150}\n",
      "0.391 (+/-0.180) for {'estimator__max_depth': 14, 'estimator__n_estimators': 200}\n",
      "0.395 (+/-0.138) for {'estimator__max_depth': 14, 'estimator__n_estimators': 500}\n",
      "0.413 (+/-0.141) for {'estimator__max_depth': 16, 'estimator__n_estimators': 100}\n",
      "0.403 (+/-0.125) for {'estimator__max_depth': 16, 'estimator__n_estimators': 150}\n",
      "0.411 (+/-0.147) for {'estimator__max_depth': 16, 'estimator__n_estimators': 200}\n",
      "0.431 (+/-0.105) for {'estimator__max_depth': 16, 'estimator__n_estimators': 500}\n",
      "0.435 (+/-0.106) for {'estimator__max_depth': 18, 'estimator__n_estimators': 100}\n",
      "0.426 (+/-0.105) for {'estimator__max_depth': 18, 'estimator__n_estimators': 150}\n",
      "0.425 (+/-0.097) for {'estimator__max_depth': 18, 'estimator__n_estimators': 200}\n",
      "0.420 (+/-0.117) for {'estimator__max_depth': 18, 'estimator__n_estimators': 500}\n",
      "0.433 (+/-0.100) for {'estimator__max_depth': 20, 'estimator__n_estimators': 100}\n",
      "0.416 (+/-0.110) for {'estimator__max_depth': 20, 'estimator__n_estimators': 150}\n",
      "0.414 (+/-0.109) for {'estimator__max_depth': 20, 'estimator__n_estimators': 200}\n",
      "0.421 (+/-0.117) for {'estimator__max_depth': 20, 'estimator__n_estimators': 500}\n",
      "0.438 (+/-0.100) for {'estimator__max_depth': 22, 'estimator__n_estimators': 100}\n",
      "0.411 (+/-0.086) for {'estimator__max_depth': 22, 'estimator__n_estimators': 150}\n",
      "0.414 (+/-0.094) for {'estimator__max_depth': 22, 'estimator__n_estimators': 200}\n",
      "0.405 (+/-0.117) for {'estimator__max_depth': 22, 'estimator__n_estimators': 500}\n",
      "()\n",
      "Detailed classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.75      0.24      0.37      2088\n",
      "      Adventure       0.71      0.14      0.23      1299\n",
      "      Animation       0.87      0.20      0.32       568\n",
      "         Comedy       0.75      0.29      0.41      2851\n",
      "          Crime       0.61      0.26      0.37      1190\n",
      "    Documentary       0.00      0.00      0.00       128\n",
      "          Drama       0.72      0.65      0.68      4213\n",
      "         Family       0.85      0.07      0.13       826\n",
      "        Fantasy       0.67      0.05      0.09       754\n",
      "        Foreign       0.00      0.00      0.00        30\n",
      "        History       1.00      0.00      0.01       312\n",
      "         Horror       0.82      0.20      0.33      1038\n",
      "          Music       0.40      0.01      0.02       230\n",
      "        Mystery       0.61      0.03      0.06       633\n",
      "        Romance       0.72      0.25      0.37      1489\n",
      "Science Fiction       0.85      0.34      0.49       908\n",
      "       TV Movie       0.00      0.00      0.00        89\n",
      "       Thriller       0.66      0.25      0.37      2374\n",
      "            War       0.68      0.24      0.35       273\n",
      "        Western       1.00      0.01      0.01       168\n",
      "\n",
      "    avg / total       0.72      0.29      0.38     21461\n",
      "\n",
      "\n",
      "**** Per genre accuracy ****\n",
      "\n",
      "\n",
      "Action accuracy:\t0.800\n",
      "Adventure accuracy:\t0.864\n",
      "Animation accuracy:\t0.946\n",
      "Comedy accuracy:\t0.737\n",
      "Crime accuracy:\t0.877\n",
      "Documentary accuracy:\t0.985\n",
      "Drama accuracy:\t0.709\n",
      "Family accuracy:\t0.911\n",
      "Fantasy accuracy:\t0.916\n",
      "Foreign accuracy:\t0.997\n",
      "History accuracy:\t0.965\n",
      "Horror accuracy:\t0.900\n",
      "Music accuracy:\t0.974\n",
      "Mystery accuracy:\t0.929\n",
      "Romance accuracy:\t0.856\n",
      "Science Fiction accuracy:\t0.925\n",
      "TV Movie accuracy:\t0.990\n",
      "Thriller accuracy:\t0.763\n",
      "War accuracy:\t0.973\n",
      "Western accuracy:\t0.981\n",
      "\n",
      "**** OTHER METRICS ****\n",
      "\n",
      "\n",
      "Overall accuracy:\t0.115\n",
      "Average per-genre accuracy:\t0.900\n",
      "Hamming loss:\t\t0.100\n",
      "Zero one loss:\t\t0.885\n",
      "Jaccard similarity:\t0.302\n",
      "\n",
      "**** compare this result with random labeling ****\n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.28      0.15      0.20      2088\n",
      "      Adventure       0.16      0.13      0.14      1299\n",
      "      Animation       0.07      0.13      0.09       568\n",
      "         Comedy       0.31      0.12      0.17      2851\n",
      "          Crime       0.15      0.13      0.14      1190\n",
      "    Documentary       0.01      0.11      0.02       128\n",
      "          Drama       0.50      0.13      0.20      4213\n",
      "         Family       0.10      0.12      0.11       826\n",
      "        Fantasy       0.09      0.12      0.10       754\n",
      "        Foreign       0.00      0.03      0.00        30\n",
      "        History       0.04      0.12      0.06       312\n",
      "         Horror       0.12      0.12      0.12      1038\n",
      "          Music       0.02      0.12      0.04       230\n",
      "        Mystery       0.07      0.12      0.09       633\n",
      "        Romance       0.16      0.12      0.14      1489\n",
      "Science Fiction       0.12      0.14      0.13       908\n",
      "       TV Movie       0.01      0.10      0.02        89\n",
      "       Thriller       0.26      0.12      0.16      2374\n",
      "            War       0.03      0.11      0.05       273\n",
      "        Western       0.02      0.15      0.04       168\n",
      "\n",
      "    avg / total       0.25      0.13      0.15     21461\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"All, sampling 0.1 of all, normalized\")\n",
    "param_01rf2, class_report_01rf2, y_test_pred_01rf2 =\\\n",
    "    tune_rf(X_train_std, y1_train01, X_test_std, y1_test01, y1_test01random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation\n",
    "Compared to the *SVM* classifier, this model provides an higher *precision* and a far lower *recall* average recall value. It means that, given a positive sample, the classifier will fail to detect it more frequently but, given a positive prediction from the classifier, this prediciton will be more likely correct. This is not entirely positive for our use case, as it means that we will more often fail to assign the correct genre to the movies.\n",
    "\n",
    "This behaviour is reflected also by the values obtained in the *jaccard score* and *F1 value*, which are lower compared to the SVM case. Oddly enough, the *hamming loss* is slightly lower compared to the SVM case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Investigate movie posters\n",
    "We initially downloaded 500 pixels wide, color, posters in order to feed our models with movie poster data. Each poster was 750x500x3 byte, roughly making ~1MB of uncompressed color data per poster. The color data was vectorized, so that the data for each channel was appended to a single vector.\n",
    "\n",
    "We had to standardize the poster data and apply PCA to reduce the dimensionality of our problem: the PCA found that we could explain 90% of the variance in the data by retaining the first 100 principal components, drastically reducing the dimension of our problem. However, training an SVM model with rbf kernel on a train set of 1000 posters proved to be quite challenging on local machines: memory quickly became our bottleneck.\n",
    "\n",
    "We decided to reduce the dimension of the poster images to 138x92 pixels, retaining the RGB data. This allowed us to feed our algorithms with 5000 samples without loosing the color information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the dataset files\n",
    "As reported in Milestone 1, we built an external library to fetch the data from IMDB and TMDB. We load the dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "TMDB_all = pd.read_pickle(\"../data/metadata_export\")[:num_samples]\n",
    "TMDB_img = tables.open_file(\"../data/image_export.h5\", \"r\").get_node(\"/images\")[:num_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess image data\n",
    "We need to make sure all images have the same size, otherwise PCA will fail. Let's investigate the most frequent poster sizes in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 18)\n",
      "(5000L, 138L, 92L, 3L)\n"
     ]
    }
   ],
   "source": [
    "print TMDB_all.shape\n",
    "print TMDB_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TMDB_img = TMDB_img.reshape((5000, 138 * 92 * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((38088L,), 5000)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of all the poster sizes.\n",
    "image_size_dict = {}\n",
    "for img in TMDB_img:\n",
    "    image_size_dict[img.shape] = image_size_dict.get(img.shape, 0) + 1\n",
    "\n",
    "# Pick the most frequent 5, just to have a look at them.\n",
    "top5_resolutions = sorted(image_size_dict.items(), key=operator.itemgetter(1))[-5:]\n",
    "# Pick the most frequent resolution\n",
    "top_resolution = top5_resolutions[-1][0]\n",
    "top5_resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the multi-label classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_binarizer = MultiLabelBinarizer()\n",
    "TMDB_binarized_outcome = label_binarizer.fit_transform(TMDB_all[\"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Action', u'Adventure', u'Animation', u'Comedy', u'Crime',\n",
       "       u'Documentary', u'Drama', u'Family', u'Fantasy', u'History',\n",
       "       u'Horror', u'Music', u'Mystery', u'Romance', u'Science Fiction',\n",
       "       u'TV Movie', u'Thriller', u'War', u'Western'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the train, test and validation sets\n",
    "We build a training set that has the same proportion of labels as the full dataset, so that every genre is represented.\n",
    "\n",
    "We start sampling from the least frequent class to the most frequent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV Movie occurs 36 times in the full set and 33 in the train set\n",
      "Documentary occurs 41 times in the full set and 35 in the train set\n",
      "Western occurs 101 times in the full set and 92 in the train set\n",
      "Music occurs 136 times in the full set and 130 in the train set\n",
      "War occurs 172 times in the full set and 162 in the train set\n",
      "History occurs 199 times in the full set and 177 in the train set\n",
      "Animation occurs 383 times in the full set and 366 in the train set\n",
      "Mystery occurs 442 times in the full set and 423 in the train set\n",
      "Fantasy occurs 537 times in the full set and 509 in the train set\n",
      "Family occurs 547 times in the full set and 511 in the train set\n",
      "Horror occurs 591 times in the full set and 525 in the train set\n",
      "Science Fiction occurs 640 times in the full set and 584 in the train set\n",
      "Crime occurs 815 times in the full set and 744 in the train set\n",
      "Romance occurs 835 times in the full set and 754 in the train set\n",
      "Adventure occurs 931 times in the full set and 831 in the train set\n",
      "Action occurs 1371 times in the full set and 1182 in the train set\n",
      "Comedy occurs 1551 times in the full set and 1287 in the train set\n",
      "Thriller occurs 1555 times in the full set and 1307 in the train set\n",
      "Drama occurs 2320 times in the full set and 1856 in the train set\n"
     ]
    }
   ],
   "source": [
    "# Compute the frequency for each genre. Please note that the sums can\n",
    "# be greater than the number of available movies, as the labels are not\n",
    "# mutually exclusive.\n",
    "genre_counts = {}\n",
    "for genre in GENRE_LIST:\n",
    "    genre_counts[genre] = TMDB_all['genres'].apply(lambda x: genre in x).sum()\n",
    "\n",
    "# Sort the genres from the least occurring to the most frequent.\n",
    "num_movies = TMDB_all.shape[0]\n",
    "sorted_genres = sorted(genre_counts.items(), key=operator.itemgetter(1))\n",
    "\n",
    "train_set_size = 0.8\n",
    "\n",
    "# Generate a train/test set.\n",
    "train_set = pd.DataFrame()\n",
    "original_set = TMDB_all.copy()\n",
    "for genre, count in sorted_genres:\n",
    "    # Check how many samples have this label in the set.\n",
    "    # The dataframe may be empty on the first run, so account for\n",
    "    # that.\n",
    "    already_sampled = 0\n",
    "    if 'genres' in train_set:\n",
    "        already_sampled = train_set['genres'].apply(lambda x: genre in x).sum()\n",
    "        \n",
    "    # If the test set already contains all the samples we expect\n",
    "    # for this label, continue to the next label.\n",
    "    expected_samples = int(math.floor(train_set_size * count))\n",
    "    if already_sampled >= expected_samples:\n",
    "        continue\n",
    "\n",
    "    # If not, then randomly sample |expected - already_there| samples\n",
    "    num_to_sample = expected_samples - already_sampled\n",
    "    samples = original_set[original_set['genres'].apply(lambda x: genre in x)]\\\n",
    "                                                 .sample(n=num_to_sample, random_state = 42)\n",
    "    # Append the random samples to the train_set\n",
    "    train_set = train_set.append(samples)\n",
    "    # Remove them from the original set, so we don't sample them again\n",
    "    # for a different label.\n",
    "    original_set = original_set.drop(samples.index)\n",
    "    \n",
    "# Verify that the genre proportions are kept in the train set.\n",
    "for genre, count in sorted_genres:\n",
    "    print(\"{} occurs {} times in the full set and {} in the train set\"\\\n",
    "          .format(genre, count,  train_set['genres'].apply(lambda x: genre in x).sum()))\n",
    "    \n",
    "# Build a test set, by difference.\n",
    "test_set = TMDB_all.drop(train_set.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a SVM classifier on Poster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize the posters.\n",
    "standardized_posters = StandardScaler().fit_transform(TMDB_img.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(standardized_posters[train_set.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30157971,  0.36475684,  0.41017664,  0.44483254,  0.46960256,\n",
       "        0.49164431,  0.50950769,  0.52392082,  0.53475083,  0.54480542,\n",
       "        0.55443467,  0.56336389,  0.57115836,  0.57850479,  0.58544517,\n",
       "        0.5921212 ,  0.59831321,  0.60428034,  0.60961437,  0.61484049,\n",
       "        0.61987665,  0.62467522,  0.62932932,  0.63345395,  0.63750908,\n",
       "        0.64142855,  0.64519294,  0.64877207,  0.65221904,  0.6555591 ,\n",
       "        0.65867536,  0.66173929,  0.66464521,  0.6674424 ,  0.67009831,\n",
       "        0.67272362,  0.67529259,  0.67781786,  0.68028342,  0.68265952,\n",
       "        0.68494692,  0.68716383,  0.68934213,  0.69149258,  0.69359327,\n",
       "        0.69564157,  0.69766309,  0.69961495,  0.70154563,  0.70342696,\n",
       "        0.70521416,  0.70696227,  0.70868087,  0.7103779 ,  0.7120733 ,\n",
       "        0.71373523,  0.71533551,  0.71689277,  0.7184294 ,  0.71991512,\n",
       "        0.72137023,  0.72277609,  0.72417113,  0.7255613 ,  0.72690943,\n",
       "        0.72823495,  0.72955313,  0.73086973,  0.73214972,  0.73339006,\n",
       "        0.73462061,  0.73583114,  0.73702188,  0.73820339,  0.73936402,\n",
       "        0.74051412,  0.74165978,  0.74278001,  0.74387521,  0.74496045,\n",
       "        0.7460318 ,  0.74708409,  0.74812596,  0.74914356,  0.75015109,\n",
       "        0.75113949,  0.75210919,  0.75306977,  0.75401991,  0.75495123,\n",
       "        0.75587646,  0.75677744,  0.75766163,  0.75854436,  0.75942647,\n",
       "        0.76028066,  0.7611241 ,  0.76194525,  0.76276332,  0.76357256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project the input data into the PCA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_projected_posters = pca.transform(standardized_posters[train_set.index])\n",
    "test_projected_posters = pca.transform(standardized_posters[test_set.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] estimator__C=0.001, estimator__gamma=1e-05 ......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=1e-05, score=0.000000, total=   9.5s\n",
      "[CV] estimator__C=0.001, estimator__gamma=1e-05 ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__C=0.001, estimator__gamma=1e-05, score=0.000000, total=  10.6s\n",
      "[CV] estimator__C=0.001, estimator__gamma=1e-05 ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   45.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__C=0.001, estimator__gamma=1e-05, score=0.000000, total=  10.1s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.01 .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__C=0.001, estimator__gamma=0.01, score=0.000000, total=  10.2s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.01 .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  estimator__C=0.001, estimator__gamma=0.01, score=0.000000, total=  11.1s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.01, score=0.000000, total=  11.3s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.001 ......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.001, score=0.000000, total=   9.8s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.001 ......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.001, score=0.000000, total=  10.5s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.001 ......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.001, score=0.000000, total=  10.1s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.01, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.01, score=0.000000, total=  11.1s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.01, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.1 ........................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.1, score=0.000000, total=  11.0s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.1 ........................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.1, score=0.000000, total=  12.0s\n",
      "[CV] estimator__C=0.001, estimator__gamma=0.1 ........................\n",
      "[CV]  estimator__C=0.001, estimator__gamma=0.1, score=0.000000, total=  11.6s\n",
      "[CV] estimator__C=0.01, estimator__gamma=1e-05 .......................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=1e-05, score=0.000000, total=   9.4s\n",
      "[CV] estimator__C=0.01, estimator__gamma=1e-05 .......................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=1e-05, score=0.000000, total=  10.4s\n",
      "[CV] estimator__C=0.01, estimator__gamma=1e-05 .......................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=1e-05, score=0.000000, total=  10.1s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.01, score=0.000000, total=  10.5s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.01, score=0.000000, total=  11.1s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.01, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.001 .......................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.001, score=0.000000, total=   9.7s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.001 .......................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.001, score=0.000000, total=  10.3s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.001 .......................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.001, score=0.000000, total=  10.5s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.01, score=0.000000, total=  10.4s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.01, score=0.000000, total=  10.9s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.01, score=0.000000, total=  11.0s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.1 .........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.1, score=0.000000, total=  10.9s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.1 .........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.1, score=0.000000, total=  11.6s\n",
      "[CV] estimator__C=0.01, estimator__gamma=0.1 .........................\n",
      "[CV]  estimator__C=0.01, estimator__gamma=0.1, score=0.000000, total=  11.7s\n",
      "[CV] estimator__C=1.0, estimator__gamma=1e-05 ........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=1e-05, score=0.000739, total=   6.3s\n",
      "[CV] estimator__C=1.0, estimator__gamma=1e-05 ........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=1e-05, score=0.001479, total=   7.8s\n",
      "[CV] estimator__C=1.0, estimator__gamma=1e-05 ........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=1e-05, score=0.000000, total=   8.2s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.01 .........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.01, score=0.000000, total=  11.0s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.01 .........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.01, score=0.000740, total=  11.1s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.01 .........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.01, score=0.000740, total=  11.3s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.001 ........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.001, score=0.000000, total=  10.6s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.001 ........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.001, score=0.000740, total=  10.8s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.001 ........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.001, score=0.000740, total=  10.6s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.01 .........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.01, score=0.000000, total=  10.8s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.01 .........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.01, score=0.000740, total=  11.5s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.01 .........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.01, score=0.000740, total=  11.2s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.1 ..........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.1, score=0.000000, total=  11.5s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.1 ..........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.1, score=0.000740, total=  12.0s\n",
      "[CV] estimator__C=1.0, estimator__gamma=0.1 ..........................\n",
      "[CV]  estimator__C=1.0, estimator__gamma=0.1, score=0.000740, total=  11.8s\n",
      "[CV] estimator__C=10.0, estimator__gamma=1e-05 .......................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=1e-05, score=0.002956, total=   5.6s\n",
      "[CV] estimator__C=10.0, estimator__gamma=1e-05 .......................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=1e-05, score=0.005178, total=   6.9s\n",
      "[CV] estimator__C=10.0, estimator__gamma=1e-05 .......................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=1e-05, score=0.005917, total=   6.9s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.01, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.01, score=0.000740, total=  11.7s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.01, score=0.000740, total=  11.0s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.001 .......................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.001, score=0.000000, total=  10.2s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.001 .......................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.001, score=0.000740, total=  10.8s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.001 .......................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.001, score=0.000740, total=  10.9s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.01, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.01, score=0.000740, total=  11.1s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.01 ........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.01, score=0.000740, total=  11.2s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.1 .........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.1, score=0.000000, total=  11.3s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.1 .........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.1, score=0.000740, total=  12.1s\n",
      "[CV] estimator__C=10.0, estimator__gamma=0.1 .........................\n",
      "[CV]  estimator__C=10.0, estimator__gamma=0.1, score=0.000740, total=  11.6s\n",
      "[CV] estimator__C=100.0, estimator__gamma=1e-05 ......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=1e-05, score=0.000739, total=   6.1s\n",
      "[CV] estimator__C=100.0, estimator__gamma=1e-05 ......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=1e-05, score=0.004438, total=   6.8s\n",
      "[CV] estimator__C=100.0, estimator__gamma=1e-05 ......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=1e-05, score=0.009615, total=   7.8s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.01, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.01, score=0.000740, total=  11.3s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.01, score=0.000740, total=  11.7s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.001 ......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.001, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.001 ......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.001, score=0.000740, total=  10.6s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.001 ......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.001, score=0.000740, total=  11.0s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.01, score=0.000000, total=  10.9s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.01, score=0.000740, total=  11.2s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.01 .......................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.01, score=0.000740, total=  11.3s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.1 ........................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.1, score=0.000000, total=  11.3s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.1 ........................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.1, score=0.000740, total=  11.7s\n",
      "[CV] estimator__C=100.0, estimator__gamma=0.1 ........................\n",
      "[CV]  estimator__C=100.0, estimator__gamma=0.1, score=0.000740, total=  12.0s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=1e-05 .....................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=1e-05, score=0.000739, total=   6.9s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=1e-05 .....................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=1e-05, score=0.008876, total=   7.4s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=1e-05 .....................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=1e-05, score=0.013314, total=   8.5s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.01 ......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.01, score=0.000000, total=  10.7s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.01 ......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.01, score=0.000740, total=  10.9s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.01 ......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.01, score=0.000740, total=  11.0s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.001 .....................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.001, score=0.000000, total=  10.3s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.001 .....................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.001, score=0.000740, total=  10.6s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.001 .....................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.001, score=0.000740, total=  10.6s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.01 ......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.01, score=0.000000, total=  10.5s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.01 ......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.01, score=0.000740, total=  11.0s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.01 ......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.01, score=0.000740, total=  11.0s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.1 .......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.1, score=0.000000, total=  11.3s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.1 .......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.1, score=0.000740, total=  11.6s\n",
      "[CV] estimator__C=1000.0, estimator__gamma=0.1 .......................\n",
      "[CV]  estimator__C=1000.0, estimator__gamma=0.1, score=0.000740, total=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed: 35.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=-1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.001, 0.01, 1.0, 10.0, 100.0, 1000.0], 'estimator__gamma': [1e-05, 0.01, 0.001, 0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'estimator__C': [0.001, 0.01, 1.0, 10.0, 100.0, 1000.0],\n",
    "    'estimator__gamma': [10e-6, 10e-3, 0.001, 0.01, 0.1]\n",
    "}\n",
    "svr = OneVsRestClassifier(SVC(kernel='rbf', class_weight='balanced'), n_jobs=-1)\n",
    "clf = GridSearchCV(svr, parameters, cv=3, verbose=5)\n",
    "clf.fit(train_projected_posters, TMDB_binarized_outcome[train_set.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99556322405718511"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_projected_posters, TMDB_binarized_outcome[train_set.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029692470837751856"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_projected_posters, TMDB_binarized_outcome[test_set.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.21      0.30      0.25       189\n",
      "      Adventure       0.15      0.29      0.20       100\n",
      "      Animation       0.06      0.24      0.09        17\n",
      "         Comedy       0.45      0.45      0.45       264\n",
      "          Crime       0.09      0.20      0.12        71\n",
      "    Documentary       0.00      0.00      0.00         6\n",
      "          Drama       0.56      0.53      0.54       464\n",
      "         Family       0.09      0.22      0.12        36\n",
      "        Fantasy       0.04      0.14      0.06        28\n",
      "        History       0.00      0.00      0.00        22\n",
      "         Horror       0.16      0.26      0.20        66\n",
      "          Music       0.00      0.00      0.00         6\n",
      "        Mystery       0.04      0.21      0.07        19\n",
      "        Romance       0.16      0.33      0.21        81\n",
      "Science Fiction       0.10      0.21      0.13        56\n",
      "       TV Movie       0.00      0.00      0.00         3\n",
      "       Thriller       0.35      0.43      0.39       248\n",
      "            War       0.00      0.00      0.00        10\n",
      "        Western       0.00      0.00      0.00         9\n",
      "\n",
      "    avg / total       0.33      0.38      0.35      1695\n",
      "\n",
      "\n",
      "**** Per genre accuracy ****\n",
      "\n",
      "\n",
      "Action accuracy:\t0.631\n",
      "Adventure accuracy:\t0.748\n",
      "Animation accuracy:\t0.917\n",
      "Comedy accuracy:\t0.691\n",
      "Crime accuracy:\t0.790\n",
      "Documentary accuracy:\t0.992\n",
      "Drama accuracy:\t0.562\n",
      "Family accuracy:\t0.881\n",
      "Fantasy accuracy:\t0.874\n",
      "History accuracy:\t0.947\n",
      "Horror accuracy:\t0.853\n",
      "Music accuracy:\t0.980\n",
      "Mystery accuracy:\t0.887\n",
      "Romance accuracy:\t0.790\n",
      "Science Fiction accuracy:\t0.836\n",
      "TV Movie accuracy:\t0.995\n",
      "Thriller accuracy:\t0.643\n",
      "War accuracy:\t0.964\n",
      "Western accuracy:\t0.981\n",
      "\n",
      "**** OTHER METRICS ****\n",
      "\n",
      "\n",
      "Overall accuracy:\t0.030\n",
      "Per-genre accuracy:\t0.840\n",
      "Hamming loss:\t\t0.160\n",
      "Zero one loss:\t\t0.970\n",
      "Jaccard similarity:\t0.213\n"
     ]
    }
   ],
   "source": [
    "detailed_report(clf.predict(test_projected_posters), TMDB_binarized_outcome[test_set.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation\n",
    "Even though we expected this classifier to perform much better, we obtained some disappointing performances: all the performance metrics are worse compared to the metadata-based models. One exception is for the average *recall* value, which is slightly higher for this model (and the one below).\n",
    "\n",
    "This is possibly related to the choice of featueres for this model, that doesn't really help correlating the image data with the *genre* of a particular movie.\n",
    "\n",
    "Even though the performances did not live up to our expectations, it seemed to perform better than the naive classifiers trained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's try a linear kernel. Use LinearSVC, as it scales up better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] estimator__C=0.001 ..............................................\n",
      "[CV] ............... estimator__C=0.001, score=0.000000, total=   7.3s\n",
      "[CV] estimator__C=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... estimator__C=0.001, score=0.001232, total=   7.8s\n",
      "[CV] estimator__C=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... estimator__C=0.001, score=0.000000, total=   7.7s\n",
      "[CV] estimator__C=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... estimator__C=0.001, score=0.000000, total=   7.4s\n",
      "[CV] estimator__C=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   30.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... estimator__C=0.001, score=0.000000, total=   7.4s\n",
      "[CV] estimator__C=0.01 ...............................................\n",
      "[CV] ................ estimator__C=0.01, score=0.001232, total=   7.0s\n",
      "[CV] estimator__C=0.01 ...............................................\n",
      "[CV] ................ estimator__C=0.01, score=0.000000, total=   7.4s\n",
      "[CV] estimator__C=0.01 ...............................................\n",
      "[CV] ................ estimator__C=0.01, score=0.000000, total=   7.4s\n",
      "[CV] estimator__C=0.01 ...............................................\n",
      "[CV] ................ estimator__C=0.01, score=0.003699, total=   7.7s\n",
      "[CV] estimator__C=0.01 ...............................................\n",
      "[CV] ................ estimator__C=0.01, score=0.016030, total=   7.5s\n",
      "[CV] estimator__C=1.0 ................................................\n",
      "[CV] ................. estimator__C=1.0, score=0.000000, total=   7.2s\n",
      "[CV] estimator__C=1.0 ................................................\n",
      "[CV] ................. estimator__C=1.0, score=0.002463, total=   7.5s\n",
      "[CV] estimator__C=1.0 ................................................\n",
      "[CV] ................. estimator__C=1.0, score=0.001233, total=   8.0s\n",
      "[CV] estimator__C=1.0 ................................................\n",
      "[CV] ................. estimator__C=1.0, score=0.002466, total=   8.0s\n",
      "[CV] estimator__C=1.0 ................................................\n",
      "[CV] ................. estimator__C=1.0, score=0.009864, total=   7.7s\n",
      "[CV] estimator__C=10.0 ...............................................\n",
      "[CV] ................ estimator__C=10.0, score=0.000000, total=   7.0s\n",
      "[CV] estimator__C=10.0 ...............................................\n",
      "[CV] ................ estimator__C=10.0, score=0.001232, total=   7.3s\n",
      "[CV] estimator__C=10.0 ...............................................\n",
      "[CV] ................ estimator__C=10.0, score=0.001233, total=   7.3s\n",
      "[CV] estimator__C=10.0 ...............................................\n",
      "[CV] ................ estimator__C=10.0, score=0.002466, total=   7.6s\n",
      "[CV] estimator__C=10.0 ...............................................\n",
      "[CV] ................ estimator__C=10.0, score=0.014797, total=   7.5s\n",
      "[CV] estimator__C=50.0 ...............................................\n",
      "[CV] ................ estimator__C=50.0, score=0.000000, total=   7.3s\n",
      "[CV] estimator__C=50.0 ...............................................\n",
      "[CV] ................ estimator__C=50.0, score=0.001232, total=   7.7s\n",
      "[CV] estimator__C=50.0 ...............................................\n",
      "[CV] ................ estimator__C=50.0, score=0.001233, total=   8.0s\n",
      "[CV] estimator__C=50.0 ...............................................\n",
      "[CV] ................ estimator__C=50.0, score=0.001233, total=   7.7s\n",
      "[CV] estimator__C=50.0 ...............................................\n",
      "[CV] ................ estimator__C=50.0, score=0.013564, total=   8.3s\n",
      "[CV] estimator__C=100.0 ..............................................\n",
      "[CV] ............... estimator__C=100.0, score=0.000000, total=   7.5s\n",
      "[CV] estimator__C=100.0 ..............................................\n",
      "[CV] ............... estimator__C=100.0, score=0.001232, total=   7.6s\n",
      "[CV] estimator__C=100.0 ..............................................\n",
      "[CV] ............... estimator__C=100.0, score=0.000000, total=   7.7s\n",
      "[CV] estimator__C=100.0 ..............................................\n",
      "[CV] ............... estimator__C=100.0, score=0.002466, total=   7.7s\n",
      "[CV] estimator__C=100.0 ..............................................\n",
      "[CV] ............... estimator__C=100.0, score=0.008631, total=   7.7s\n",
      "[CV] estimator__C=1000.0 .............................................\n",
      "[CV] .............. estimator__C=1000.0, score=0.000000, total=   7.2s\n",
      "[CV] estimator__C=1000.0 .............................................\n",
      "[CV] .............. estimator__C=1000.0, score=0.000000, total=   7.8s\n",
      "[CV] estimator__C=1000.0 .............................................\n",
      "[CV] .............. estimator__C=1000.0, score=0.000000, total=   7.3s\n",
      "[CV] estimator__C=1000.0 .............................................\n",
      "[CV] .............. estimator__C=1000.0, score=0.002466, total=   7.4s\n",
      "[CV] estimator__C=1000.0 .............................................\n",
      "[CV] .............. estimator__C=1000.0, score=0.007398, total=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=-1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.001, 0.01, 1.0, 10.0, 50.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "parameters = {\n",
    "    'estimator__C': [0.001, 0.01, 1.0, 10.0, 50.0, 100.0, 1000.0],\n",
    "}\n",
    "svr_linearSVC = OneVsRestClassifier(LinearSVC(class_weight='balanced'), n_jobs=-1)\n",
    "clf_linearSVC = GridSearchCV(svr_linearSVC, parameters, cv=5, verbose=5)\n",
    "clf_linearSVC.fit(train_projected_posters, TMDB_binarized_outcome[train_set.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.26      0.51      0.35       189\n",
      "      Adventure       0.13      0.41      0.20       100\n",
      "      Animation       0.04      0.29      0.07        17\n",
      "         Comedy       0.44      0.62      0.51       264\n",
      "          Crime       0.11      0.42      0.18        71\n",
      "    Documentary       0.00      0.00      0.00         6\n",
      "          Drama       0.54      0.53      0.54       464\n",
      "         Family       0.07      0.39      0.12        36\n",
      "        Fantasy       0.05      0.25      0.08        28\n",
      "        History       0.02      0.09      0.03        22\n",
      "         Horror       0.16      0.68      0.26        66\n",
      "          Music       0.00      0.00      0.00         6\n",
      "        Mystery       0.04      0.16      0.06        19\n",
      "        Romance       0.12      0.40      0.18        81\n",
      "Science Fiction       0.09      0.39      0.15        56\n",
      "       TV Movie       0.00      0.00      0.00         3\n",
      "       Thriller       0.34      0.47      0.39       248\n",
      "            War       0.00      0.00      0.00        10\n",
      "        Western       0.00      0.00      0.00         9\n",
      "\n",
      "    avg / total       0.33      0.49      0.37      1695\n",
      "\n",
      "\n",
      "**** Per genre accuracy ****\n",
      "\n",
      "\n",
      "Action accuracy:\t0.610\n",
      "Adventure accuracy:\t0.659\n",
      "Animation accuracy:\t0.848\n",
      "Comedy accuracy:\t0.669\n",
      "Crime accuracy:\t0.707\n",
      "Documentary accuracy:\t0.994\n",
      "Drama accuracy:\t0.549\n",
      "Family accuracy:\t0.790\n",
      "Fantasy accuracy:\t0.831\n",
      "History accuracy:\t0.872\n",
      "Horror accuracy:\t0.735\n",
      "Music accuracy:\t0.986\n",
      "Mystery accuracy:\t0.896\n",
      "Romance accuracy:\t0.695\n",
      "Science Fiction accuracy:\t0.732\n",
      "TV Movie accuracy:\t0.989\n",
      "Thriller accuracy:\t0.619\n",
      "War accuracy:\t0.961\n",
      "Western accuracy:\t0.953\n",
      "\n",
      "**** OTHER METRICS ****\n",
      "\n",
      "\n",
      "Overall accuracy:\t0.012\n",
      "Per-genre accuracy:\t0.794\n",
      "Hamming loss:\t\t0.206\n",
      "Zero one loss:\t\t0.988\n",
      "Jaccard similarity:\t0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alessio\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "detailed_report(clf_linearSVC.predict(test_projected_posters), TMDB_binarized_outcome[test_set.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation\n",
    "As with the previous model, this SVM with a *linear* kernel did not yield any surprising result. One thing worth noting, though, is that this model produced an higher *precision*, *recall* and *F1* score compared to the other SVM model, but reported a worse *hamming loss* and *jaccard similarity*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Discussion of the differences between the models, their strengths, weaknesses, etc.\n",
    "We implemented two different strategies for predicting movie genre using:\n",
    "\n",
    "1. textual data from the movie metadata.\n",
    "2. image data from the movie posters.\n",
    "\n",
    "Intuitively, words included in the overview and keywords should be good predictors for a movie's genre. We have seen  that words like “police” and “murder” appear often in \"Crime\" movie descriptions. Similarly, words such as “evil” and “vampire” are frequent for \"Horror\" movies. Both *keywords* and *actors* seem to be particularly good features at predicting the movie's genre. SVM and Random Forest models seem to be very well suited for this kind of classification problem and, given the result we obtained, seem to generalize better than other models.\n",
    "One drawback of using movie metadata to build a model is the potential explosion in the model dimension due to semantically related lems, i.e. words that have similar meaning but different text representation.\n",
    "\n",
    "Ideally, we wanted the models using the movie posters to exploit the fact that most posters within the same genre have similar color profiles. For example, posters might be brownish for Westerns, very contrasted for Comic movies. However, we found when training our model that they also vary greatly within the genre. This is due to the design trends likely changing over time.\n",
    "Moreover, our data representation (*PCA* projected RGB data) potentially mitigated these within-genre variations, but still didn't allow our models to perform as better as the metadata ones. Therefore metadata models might generalize better.\n",
    "\n",
    "Both models suffer by the number of available labels: decreasing the number of predicted labels, by removing samples or assigning the most common label to them, greatly reduces the prediction error.\n",
    "\n",
    "# What else did we try?\n",
    "\n",
    "* Random Forest with poster data, but it didn’t perform better than SVM with a RBF kernel.\n",
    "* Random Forest with stump trees (depth = 2), again with no performance benefit over SVM.\n",
    "* SVM (rbf) with grayscale poster data, but it only mitigated the memory impact of the data, without bringing any additional benefit to the model, even if it enabled feeding it with 10000 samples.\n",
    "* SVM (linear) with both grayscale and RGB poster data. While this trained much faster than the RBF kernel, it didn’t provide any model performance benefit over SVM + rbf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
